{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of linear threshold units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?**\n",
    "\n",
    "There are several reasons why it is generally preferable to use a Logistic Regression classifier over a classical Perceptron:\n",
    "\n",
    "1. Probabilistic Output: Logistic Regression provides a probabilistic output by applying the logistic function (sigmoid) to the linear combination of inputs. It outputs a probability between 0 and 1, representing the likelihood of belonging to a specific class. In contrast, the Perceptron only provides binary outputs (0 or 1) based on a threshold function. The probabilistic nature of Logistic Regression allows for more nuanced interpretation of the model's predictions and facilitates tasks like ranking and uncertainty estimation.\n",
    "\n",
    "2. Continuous Decision Boundary: Logistic Regression models use a logistic function to model the decision boundary between classes. This allows for a smooth and continuous decision boundary, which is better suited for complex datasets with overlapping or non-linear class distributions. Perceptron, on the other hand, uses a step function, resulting in a decision boundary that is piecewise linear. The smooth decision boundary of Logistic Regression provides more flexibility and better generalization.\n",
    "\n",
    "3. Gradient-Based Optimization: Logistic Regression can be trained using gradient-based optimization algorithms, such as gradient descent, which efficiently update the model parameters to minimize the loss function. This allows for efficient and scalable training on large datasets. In contrast, the Perceptron training algorithm is based on a simple update rule that only guarantees convergence for linearly separable datasets. It may not converge or find an optimal solution for more complex datasets.\n",
    "\n",
    "To make a Perceptron equivalent to a Logistic Regression classifier, you can make the following tweaks:\n",
    "\n",
    "1. Activation Function: Replace the step function in the Perceptron with the logistic function (sigmoid). This transforms the Perceptron's output into a continuous probability between 0 and 1, making it similar to the output of Logistic Regression.\n",
    "\n",
    "2. Loss Function: Replace the Perceptron's binary cross-entropy loss with the logistic regression loss (also known as the log-loss or binary cross-entropy loss). This loss function is derived from the maximum likelihood estimation of logistic regression and is well-suited for probabilistic classification.\n",
    "\n",
    "3. Weight Update Rule: Modify the weight update rule of the Perceptron to use gradient-based optimization, such as stochastic gradient descent (SGD), to minimize the logistic regression loss. This enables the Perceptron to learn the optimal weights through iterative updates based on the gradients of the loss function.\n",
    "\n",
    "By making these tweaks, the Perceptron model will closely resemble a Logistic Regression classifier in terms of its probabilistic output, decision boundary, and optimization procedure. However, it's important to note that the Perceptron may still have limitations compared to Logistic Regression, especially in handling complex datasets and achieving optimal performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Why was the logistic activation function a key ingredient in training the first MLPs?**\n",
    "\n",
    "The logistic activation function, also known as the sigmoid function, played a key role in training the first Multilayer Perceptrons (MLPs) for several reasons:\n",
    "\n",
    "1. Non-linearity: The logistic activation function introduced non-linearity to the MLPs. The Perceptron, which was the predecessor of MLPs, used a step function as the activation function, which limited the model's representational power to linear decision boundaries. The logistic function allowed MLPs to model non-linear relationships between inputs and outputs, enabling them to learn more complex patterns and solve more diverse tasks.\n",
    "\n",
    "2. Smooth and Differentiable: The logistic function is a smooth and differentiable activation function. Differentiability is a crucial property for gradient-based optimization algorithms, such as backpropagation, which are used to train MLPs. The gradients of the logistic function can be easily computed, allowing for efficient and effective gradient updates during the learning process.\n",
    "\n",
    "3. Probabilistic Interpretation: The logistic function produces outputs in the range of 0 to 1, which can be interpreted as probabilities. This probabilistic interpretation made MLPs well-suited for binary classification tasks, where the goal is to estimate the probability of an input belonging to a specific class. The logistic function allowed MLPs to provide a probabilistic output, enabling tasks such as thresholding the probabilities to make class predictions and estimating class probabilities for ranking.\n",
    "\n",
    "4. Sigmoid Derivative: The derivative of the logistic function has a simple and elegant form, which makes backpropagation calculations more tractable. The derivative of the sigmoid function can be expressed in terms of the function itself, simplifying the computation of gradients during backpropagation. This facilitated efficient training of MLPs by allowing the gradients to be efficiently propagated through the network and updating the model's parameters.\n",
    "\n",
    "The logistic activation function, with its non-linearity, differentiability, probabilistic interpretation, and convenient derivative, provided the necessary ingredients for training the first MLPs. Its introduction allowed MLPs to overcome the limitations of linear models and paved the way for more powerful and flexible neural networks capable of learning complex patterns and solving a wide range of tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Name three popular activation functions. Can you draw them?**\n",
    "\n",
    "Here are three popular activation functions along with their mathematical definitions and visual representations:\n",
    "\n",
    "1. Sigmoid (Logistic) Activation Function:\n",
    "   Mathematical definition: f(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "   Visual representation:\n",
    "\n",
    "   ![Sigmoid Activation Function](https://miro.medium.com/v2/resize:fit:970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)\n",
    "\n",
    "2. Rectified Linear Unit (ReLU) Activation Function:\n",
    "   Mathematical definition: f(x) = max(0, x)\n",
    "\n",
    "   Visual representation:\n",
    "   \n",
    "   ![ReLU Activation Function](https://www.researchgate.net/publication/333411007/figure/fig7/AS:766785846525952@1559827400204/ReLU-activation-function.png)\n",
    "\n",
    "3. Hyperbolic Tangent (Tanh) Activation Function:\n",
    "   Mathematical definition: f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "\n",
    "   Visual representation:\n",
    "\n",
    "   ![Tanh Activation Function](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-27_at_4.23.22_PM_dcuMBJl.png)\n",
    "\n",
    "These activation functions are commonly used in neural networks for their different characteristics and properties. The sigmoid function provides a smooth and bounded activation, ReLU offers simplicity and alleviates the vanishing gradient problem, and tanh provides a shifted and scaled version of the sigmoid function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.**\n",
    "* What is the shape of the input matrix X?\n",
    "* What about the shape of the hidden layer’s weight vector Wh, and the shape of its bias vector bh?\n",
    "* What is the shape of the output layer’s weight vector Wo, and its bias vector bo?\n",
    "* What is the shape of the network’s output matrix Y?\n",
    "* Write the equation that computes the network’s output matrix Y as a function of X, Wh, bh, Wo and bo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The shape of the input matrix X would be (batch_size, 10), where batch_size represents the number of samples in a batch.\n",
    "\n",
    "2. The shape of the hidden layer's weight vector Wh would be (10, 50), as there are 10 input neurons from the previous layer and 50 neurons in the hidden layer. The shape of the bias vector bh would be (50), corresponding to the bias term for each neuron in the hidden layer.\n",
    "\n",
    "3. The shape of the output layer's weight vector Wo would be (50, 3), as there are 50 neurons in the hidden layer and 3 neurons in the output layer. The shape of the bias vector bo would be (3), corresponding to the bias term for each neuron in the output layer.\n",
    "\n",
    "4. The shape of the network's output matrix Y would be (batch_size, 3), where batch_size represents the number of samples in a batch, and 3 represents the number of output neurons in the final layer.\n",
    "\n",
    "5. The equation that computes the network's output matrix Y as a function of X, Wh, bh, Wo, and bo can be written as follows:\n",
    "\n",
    "   Z_h = ReLU(X dot Wh + bh)\n",
    "   Y = ReLU(Z_h dot Wo + bo)\n",
    "\n",
    "   Here, \"dot\" denotes matrix multiplication, and ReLU is the activation function applied element-wise. The first equation computes the output of the hidden layer, and the second equation computes the final output of the network.\n",
    "\n",
    "Note: The ReLU activation function is applied element-wise to each neuron's output in the hidden layer and output layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to classify emails into spam or ham (binary classification), you would need only one neuron in the output layer. The activation function used in the output layer for binary classification tasks is typically the sigmoid activation function. The sigmoid function squashes the output between 0 and 1, providing a probability-like interpretation where values closer to 1 represent a higher likelihood of being classified as spam, while values closer to 0 represent a higher likelihood of being classified as ham.\n",
    "\n",
    "For the MNIST dataset, which is a multi-class classification problem with 10 different digits (0-9), you would need 10 neurons in the output layer. Each neuron would represent the probability of the input belonging to a particular class. The activation function used in the output layer for multi-class classification tasks is typically the softmax activation function. The softmax function scales the outputs so that they sum up to 1, representing the probabilities of the input belonging to each class. The class with the highest probability is then chosen as the predicted class.\n",
    "\n",
    "To summarize:\n",
    "- For binary classification (spam or ham), use 1 neuron in the output layer with the sigmoid activation function.\n",
    "- For multi-class classification (MNIST digits), use 10 neurons in the output layer with the softmax activation function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is a key algorithm used in neural networks to train models by calculating the gradients of the model parameters with respect to the loss function. It is an efficient method to propagate the error back through the network, allowing the adjustment of weights and biases in each layer based on their contribution to the overall error.\n",
    "\n",
    "Here's a high-level overview of how backpropagation works:\n",
    "\n",
    "1. Forward Pass: The input data is fed through the network, and the activations and outputs of each layer are computed sequentially until the final output is obtained. The forward pass involves applying the activation function to the weighted sum of inputs in each layer.\n",
    "\n",
    "2. Loss Calculation: The output of the network is compared with the desired output, and a loss function is calculated to quantify the discrepancy between the predicted and actual values.\n",
    "\n",
    "3. Backward Pass (Backpropagation): The gradients of the loss function with respect to the parameters of the network (weights and biases) are computed by propagating the error backward from the output layer to the input layer. This is done using the chain rule of derivatives, which decomposes the gradient calculation across the layers of the network.\n",
    "\n",
    "4. Parameter Update: The gradients obtained in the backward pass are used to update the parameters of the network using an optimization algorithm (e.g., gradient descent). The parameters are adjusted in the opposite direction of the gradient to minimize the loss function.\n",
    "\n",
    "Backpropagation and reverse-mode autodiff are closely related but have some differences:\n",
    "\n",
    "- Backpropagation refers specifically to the process of computing gradients in neural networks using the chain rule and propagating the error back through the network. It is a manual implementation of the chain rule and requires the explicit definition of the network architecture and the calculation of gradients for each parameter.\n",
    "\n",
    "- Reverse-mode autodiff is a more general technique used to compute gradients efficiently in computational graphs. It can be seen as a more automated version of backpropagation. Reverse-mode autodiff automatically calculates gradients by dynamically constructing and evaluating the computational graph of the model. It performs a forward pass to compute intermediate values and then performs a backward pass to efficiently compute the gradients using the chain rule.\n",
    "\n",
    "In summary, backpropagation is a specific implementation of gradient calculation and parameter update in neural networks, while reverse-mode autodiff is a more general technique used to compute gradients efficiently in computational graphs, which includes backpropagation as a specific case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Can you list all the hyperparameters you can tweak in an MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an MLP (Multi-Layer Perceptron), several hyperparameters can be tweaked to influence the model's behavior and performance. Here are the main hyperparameters:\n",
    "\n",
    "1. Number of Hidden Layers: The number of hidden layers in the MLP.\n",
    "2. Number of Neurons per Hidden Layer: The number of neurons in each hidden layer.\n",
    "3. Activation Function: The activation function used in each neuron, such as ReLU, sigmoid, or tanh.\n",
    "4. Learning Rate: The step size used in the gradient descent optimization algorithm during parameter updates.\n",
    "5. Number of Training Epochs: The number of times the entire training dataset is passed through the model during training.\n",
    "6. Batch Size: The number of training examples used in each iteration of the training process.\n",
    "7. Regularization Techniques: Techniques like L1 or L2 regularization can be used to prevent overfitting.\n",
    "8. Dropout Rate: The fraction of neurons randomly set to zero during training to reduce overfitting.\n",
    "9. Initialization of Weights: The method used to initialize the weights of the model, such as random initialization or Xavier/Glorot initialization.\n",
    "10. Optimizer: The optimization algorithm used to update the model parameters, such as stochastic gradient descent (SGD), Adam, or RMSprop.\n",
    "\n",
    "If the MLP is overfitting the training data, meaning it performs well on the training data but poorly on new, unseen data, you can tweak these hyperparameters to address the issue:\n",
    "\n",
    "1. Reduce Model Complexity: Decrease the number of hidden layers or neurons in each layer to simplify the model and reduce its capacity to overfit.\n",
    "2. Regularization: Increase the regularization strength by adjusting the regularization hyperparameters (e.g., increase the L1 or L2 regularization term) to penalize large weights and prevent overfitting.\n",
    "3. Dropout: Increase the dropout rate to randomly drop more neurons during training, which can help reduce overfitting.\n",
    "4. Early Stopping: Monitor the model's performance on a validation set during training and stop training early when the validation error starts to increase, indicating overfitting.\n",
    "5. Data Augmentation: Increase the size and diversity of the training data by applying data augmentation techniques such as rotation, scaling, or adding noise to the input samples.\n",
    "6. Cross-Validation: Use cross-validation to evaluate the model's performance on different subsets of the training data and select hyperparameters that result in the best average performance across folds.\n",
    "\n",
    "It's important to note that the effectiveness of tweaking these hyperparameters may vary depending on the specific dataset and problem at hand. Experimentation and careful monitoring of the model's performance on both training and validation data are key to finding the optimal configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Try dding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 18s 15ms/step - loss: 0.2920 - accuracy: 0.9106 - val_loss: 0.1242 - val_accuracy: 0.9629\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1288 - accuracy: 0.9614 - val_loss: 0.0916 - val_accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.0954 - accuracy: 0.9700 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.0786 - accuracy: 0.9755 - val_loss: 0.0843 - val_accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.0790 - val_accuracy: 0.9787\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: 0.0809 - val_accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.0820 - val_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 0.0815 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.0773 - val_accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0754 - val_accuracy: 0.9810\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9820\n",
      "Test accuracy: 0.9819999933242798\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load and preprocess the MNIST dataset:\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# Define the model architecture:\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(28 * 28,)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model:\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Define callbacks for saving checkpoints and TensorBoard:\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    \"checkpoint.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs\", histogram_freq=1, write_graph=True, write_images=True\n",
    ")\n",
    "\n",
    "# Train the model:\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint_callback, tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set:\n",
    "model.load_weights(\"checkpoint.h5\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

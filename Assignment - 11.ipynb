{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - 11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Write the Python code to implement a single neuron.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron output: 0.6796076276962867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        # Initialize random weights and bias\n",
    "        self.weights = np.random.rand(input_size)\n",
    "        self.bias = np.random.rand()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Compute weighted sum of inputs and apply activation function\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        output = self.activation(weighted_sum)\n",
    "        return output\n",
    "\n",
    "    def activation(self, x):\n",
    "        # Use sigmoid activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example usage\n",
    "input_size = 2\n",
    "inputs = np.array([0.5, 0.3])\n",
    "\n",
    "neuron = Neuron(input_size)\n",
    "output = neuron.forward(inputs)\n",
    "print(\"Neuron output:\", output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Write the Python code to implement ReLU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU output: [0 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "output = relu(x)\n",
    "print(\"ReLU output:\", output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Write the Python code for a dense layer in terms of matrix multiplication.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense layer output: [0.41798632 9.46124924]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # Initialize random weights and biases\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.biases = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Perform matrix multiplication and add biases\n",
    "        output = np.dot(inputs, self.weights) + self.biases\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 3\n",
    "output_size = 2\n",
    "inputs = np.array([1, 2, 3])\n",
    "\n",
    "dense_layer = DenseLayer(input_size, output_size)\n",
    "output = dense_layer.forward(inputs)\n",
    "print(\"Dense layer output:\", output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense layer output: [3.023111356549234, 2.835824608495797]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # Initialize random weights and biases\n",
    "        self.weights = [[random.random() for _ in range(input_size)] for _ in range(output_size)]\n",
    "        self.biases = [random.random() for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Perform matrix multiplication and add biases\n",
    "        output = [sum(w * x for w, x in zip(weights, inputs)) + b for weights, b in zip(self.weights, self.biases)]\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 3\n",
    "output_size = 2\n",
    "inputs = [1, 2, 3]\n",
    "\n",
    "dense_layer = DenseLayer(input_size, output_size)\n",
    "output = dense_layer.forward(inputs)\n",
    "print(\"Dense layer output:\", output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What is the “hidden size” of a layer?**\n",
    "\n",
    "The \"hidden size\" of a layer refers to the number of neurons or units present in that layer. It represents the dimensionality or the number of features that the layer can learn and represent. In a neural network, each layer typically has a specified hidden size that determines the number of activations or outputs it produces.\n",
    "\n",
    "For example, in a dense (fully connected) layer, the hidden size corresponds to the number of neurons in that layer. In a recurrent neural network (RNN), the hidden size refers to the number of hidden states or memory cells in the RNN layer. In a convolutional neural network (CNN), the hidden size typically corresponds to the number of filters or channels in that layer.\n",
    "\n",
    "The hidden size is an important parameter that affects the capacity and representational power of the layer. It determines how complex patterns and relationships can be learned and encoded by the layer. Larger hidden sizes provide more capacity for the layer to learn intricate features but may also increase the model's complexity and computational requirements. Choosing an appropriate hidden size for a layer involves a trade-off between model capacity and computational efficiency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What does the t method do in PyTorch?**\n",
    "\n",
    "In PyTorch, the t method is used to perform the transpose operation on a tensor. It swaps the dimensions of a tensor, turning its rows into columns and vice versa. The t method can be called on a PyTorch tensor object, and it returns a new tensor with the dimensions transposed.\n",
    "\n",
    "Here's an example to illustrate the usage of the t method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Transposed tensor:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "x_transposed = x.t()\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(x)\n",
    "\n",
    "print(\"Transposed tensor:\")\n",
    "print(x_transposed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we define a tensor x with dimensions (2, 3). We call the t method on x to obtain a new tensor x_transposed, which has dimensions (3, 2). The rows of the original tensor become columns in the transposed tensor.\n",
    "\n",
    "The t method is particularly useful when working with matrices or tensors that represent tabular data, as it allows you to easily swap the rows and columns for various operations such as matrix multiplication or reshaping the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Why is matrix multiplication written in plain Python very slow?**\n",
    "\n",
    "Matrix multiplication implemented in plain Python can be slow for several reasons:\n",
    "\n",
    "1. **Iteration over elements:** In plain Python, matrix multiplication typically involves nested loops to iterate over the elements of the matrices. This leads to slow execution because Python's interpreted nature and dynamic typing introduce additional overhead compared to lower-level languages like C++ or Fortran.\n",
    "\n",
    "2. **Lack of optimized operations:** Python's built-in data types (lists or nested lists) are not optimized for numerical computations. They do not provide efficient operations like vectorized operations or hardware-accelerated implementations.\n",
    "\n",
    "3. **Function call overhead:** The use of explicit loops and function calls in plain Python adds additional overhead, especially when dealing with large matrices. Each iteration and function call incurs overhead, leading to slower execution compared to more optimized implementations.\n",
    "\n",
    "4. **Absence of parallelism:** Plain Python does not provide native support for parallel execution of matrix multiplication. Matrix multiplication is an inherently parallelizable operation, and utilizing multiple processor cores or SIMD (Single Instruction, Multiple Data) instructions can significantly accelerate the computation. However, in plain Python, parallelism needs to be manually implemented, which adds complexity and may not achieve the same level of performance as optimized libraries.\n",
    "\n",
    "To overcome these performance limitations, it is common to use optimized libraries and frameworks like NumPy or TensorFlow that provide efficient implementations of matrix multiplication using lower-level languages or hardware acceleration. These libraries leverage highly optimized algorithms, data structures, and parallelization techniques, resulting in significant speed improvements compared to plain Python implementations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. In matmul, why is ac==br?**\n",
    "\n",
    "In matrix multiplication (often denoted as `matmul` or the `@` operator in Python), the condition `ac == br` refers to the compatibility condition that must be satisfied for two matrices to be multiplied together.\n",
    "\n",
    "In the notation `A @ B = C`, where `A` is a matrix of shape `(a, c)`, `B` is a matrix of shape `(b, r)`, and `C` is the resulting matrix of shape `(a, r)`, the compatibility condition `ac == br` ensures that the number of columns in the left matrix (`A`) matches the number of rows in the right matrix (`B`).\n",
    "\n",
    "To understand why this condition is necessary, consider the mechanics of matrix multiplication. In the resulting matrix `C`, each element `C[i][j]` is obtained by taking the dot product of the `i`-th row of matrix `A` and the `j`-th column of matrix `B`. For this dot product to be well-defined, the number of elements in the row of `A` (which is equal to the number of columns in `A`) must be equal to the number of elements in the column of `B` (which is equal to the number of rows in `B`).\n",
    "\n",
    "When `ac != br`, the number of columns in `A` does not match the number of rows in `B`, and the dot product operation cannot be performed. Therefore, the matrices are not compatible for multiplication, and an error will be raised.\n",
    "\n",
    "It's important to note that the resulting matrix `C` will have dimensions `(a, r)`, where `a` corresponds to the number of rows in matrix `A` and `r` corresponds to the number of columns in matrix `B`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?**\n",
    "\n",
    "In Jupyter Notebook, you can measure the time taken for a single cell to execute using the `%time` or `%%time` magic commands. \n",
    "\n",
    "To measure the time taken for a single line of code within a cell, you can prefix the line with `%time`. For example:\n",
    "```python\n",
    "%time my_function()\n",
    "```\n",
    "This will output the execution time for `my_function()`.\n",
    "\n",
    "To measure the time taken for the entire cell to execute, you can use `%%time` at the beginning of the cell. For example:\n",
    "```python\n",
    "%%time\n",
    "# Code block to measure execution time\n",
    "my_function1()\n",
    "my_function2()\n",
    "```\n",
    "This will display the execution time for the entire code block within the cell.\n",
    "\n",
    "The `%time` and `%%time` commands provide detailed timing information, including the CPU time, wall time, and other metrics.\n",
    "\n",
    "You can also use `%timeit` or `%%timeit` to perform a more accurate timing measurement by running the code multiple times and averaging the results. This is particularly useful when you want to measure the execution time of short-running code snippets.\n",
    "\n",
    "Note that these timing commands are specific to Jupyter Notebook and may not work in other Python environments or IDEs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. What is elementwise arithmetic?**\n",
    "\n",
    "Elementwise arithmetic refers to performing arithmetic operations (such as addition, subtraction, multiplication, and division) on corresponding elements of two or more arrays or matrices. In this operation, the arithmetic operation is applied independently to each element in the arrays, without any interaction or dependency between the elements.\n",
    "\n",
    "Elementwise arithmetic allows you to apply the same arithmetic operation to multiple elements simultaneously, which is particularly useful when working with arrays or matrices. It simplifies the syntax and improves the efficiency of performing operations on a large number of elements.\n",
    "\n",
    "For example, consider two arrays `A = [1, 2, 3]` and `B = [4, 5, 6]`. Performing elementwise addition would result in a new array `C = [5, 7, 9]`, where each element of `C` is obtained by adding the corresponding elements from `A` and `B`.\n",
    "\n",
    "In Python, elementwise arithmetic operations can be performed using various libraries and frameworks like NumPy or TensorFlow. These libraries provide efficient implementations that leverage optimized algorithms and vectorized operations to perform elementwise arithmetic efficiently on arrays and matrices.\n",
    "\n",
    "Here's an example of elementwise addition using NumPy:\n",
    "\n",
    "In this example, the `+` operator performs elementwise addition on the arrays `A` and `B`, resulting in the array `C`. Each element of `C` is obtained by adding the corresponding elements from `A` and `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 5, 6])\n",
    "\n",
    "C = A + B  # Elementwise addition\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Write the PyTorch code to test whether every element of a is greater than the corresponding element of b.**\n",
    "\n",
    "In this code, we define two PyTorch tensors a and b, each containing a sequence of numbers. The expression a > b performs elementwise comparison, resulting in a Boolean tensor with True values where the condition a > b is satisfied for each element.\n",
    "\n",
    "The torch.all() function is then used to check if all elements of the resulting tensor are True. It returns a single Boolean value indicating whether the condition is true for every element in the tensor. If all elements of a are greater than the corresponding elements of b, the result variable will be True; otherwise, it will be False.\n",
    "\n",
    "In the example provided, since all elements of a are indeed greater than the corresponding elements of b, the output will be True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([0, 2, 2])\n",
    "\n",
    "result = torch.all(a > b)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. What is a rank-0 tensor? How do you convert it to a plain Python data type?**\n",
    "\n",
    "In TensorFlow, a rank-0 tensor is also referred to as a scalar tensor. It represents a single value, such as a single number, without any dimensions or axes. A rank-0 tensor is essentially a 0-dimensional array.\n",
    "\n",
    "To convert a rank-0 tensor to a plain Python data type, you can use the .numpy() method to extract the underlying value as a NumPy array, and then access the value using indexing. Since a rank-0 tensor represents a single value, the extracted NumPy array will also be a 0-dimensional array.\n",
    "\n",
    "Here's an example to illustrate the conversion of a rank-0 tensor to a plain Python data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a rank-0 tensor (scalar tensor)\n",
    "tensor = tf.constant(42)\n",
    "\n",
    "# Convert the rank-0 tensor to a plain Python data type\n",
    "value = tensor.numpy()[()]\n",
    "\n",
    "print(value)\n",
    "print(type(value))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we create a rank-0 tensor tensor using tf.constant(42), which represents the scalar value 42. We then convert the tensor to a NumPy array using .numpy(), and access the value using [()] indexing. The resulting value is a plain Python integer 42, and we verify its type using the type() function.\n",
    "\n",
    "Note that the [()] indexing is necessary to extract the scalar value as a plain Python data type. It retrieves the single value from the 0-dimensional NumPy array.\n",
    "\n",
    "By using this approach, you can convert a rank-0 tensor (scalar tensor) to a plain Python data type for further processing or usage in Python code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. How does elementwise arithmetic help us speed up matmul?**\n",
    "\n",
    "Elementwise arithmetic, by itself, does not directly speed up matrix multiplication (`matmul`) operations. Elementwise arithmetic refers to performing arithmetic operations on corresponding elements of two arrays or matrices independently.\n",
    "\n",
    "However, elementwise arithmetic can be combined with optimized matrix multiplication algorithms and frameworks (such as NumPy or TensorFlow) to improve the overall efficiency and performance of matrix multiplication operations.\n",
    "\n",
    "One common approach is to leverage optimized implementations of matrix multiplication provided by these frameworks, which internally utilize highly optimized libraries (such as BLAS or cuBLAS) and optimized algorithms (such as Strassen's algorithm or the Coppersmith-Winograd algorithm) to efficiently compute matrix products.\n",
    "\n",
    "By using these optimized implementations, the matrix multiplication operation can take advantage of parallel processing, vectorized operations, and efficient memory access patterns, which can lead to significant speed improvements compared to naive or plain Python implementations of matrix multiplication.\n",
    "\n",
    "Elementwise arithmetic can be used in combination with optimized matrix multiplication to perform computations that involve both elementwise operations and matrix multiplication. For example, if you need to perform an elementwise operation (e.g., elementwise addition or multiplication) on two matrices before or after the matrix multiplication step, you can leverage the optimized matrix multiplication algorithm and perform the elementwise operations efficiently as well.\n",
    "\n",
    "It's important to note that while elementwise arithmetic alone does not speed up matrix multiplication, utilizing optimized matrix multiplication algorithms and frameworks, along with appropriate use of elementwise arithmetic, can collectively lead to efficient and faster computations involving matrix multiplication."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. What are the broadcasting rules?**\n",
    "\n",
    "Broadcasting is a feature in NumPy (and other array-based libraries) that allows arrays with different shapes to be combined in arithmetic operations. When performing elementwise operations between arrays of different shapes, NumPy automatically applies broadcasting rules to make the arrays compatible for the operation.\n",
    "\n",
    "The broadcasting rules define how arrays with different shapes are matched and expanded to perform elementwise operations. The rules are as follows:\n",
    "\n",
    "Rule 1: If the arrays have different numbers of dimensions, the array with fewer dimensions is padded with ones on its left side until the number of dimensions matches.\n",
    "\n",
    "Rule 2: If the shape of any dimension in the arrays does not match, and one of them has a size of 1 for that dimension, the array with size 1 is stretched along that dimension to match the size of the other array.\n",
    "\n",
    "Rule 3: If the shape of any dimension in the arrays does not match, and neither array has a size of 1 for that dimension, a \"broadcasting error\" occurs, indicating that the arrays cannot be broadcasted.\n",
    "\n",
    "To illustrate these rules, consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 22 33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3]])  # Shape: (1, 3)\n",
    "B = np.array([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "C = A + B\n",
    "\n",
    "print(C)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have two arrays A and B. Array A has shape (1, 3), and array B has shape (3,). According to the broadcasting rules:\n",
    "\n",
    "Rule 1: Array B is padded with an additional dimension on the left to match the number of dimensions in A. Now, B has shape (1, 3).\n",
    "Rule 2: Array B is stretched along the first dimension to match the size of A along that dimension.\n",
    "Rule 3: Since the shape of both arrays now matches, the elementwise addition is performed, resulting in the array C with shape (1, 3).\n",
    "\n",
    "The broadcasting rules allow us to perform elementwise operations between arrays with different shapes efficiently and without explicitly duplicating or reshaping the arrays. It simplifies the syntax and enables concise and readable code when working with arrays in NumPy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. What is expand_as? Show an example of how it can be used to match the results of broadcasting.**\n",
    "\n",
    "In PyTorch, the expand_as method is used to expand the dimensions of a tensor to match the shape of another tensor. It is commonly used to ensure that two tensors have compatible shapes for elementwise operations, similar to how broadcasting works in NumPy.\n",
    "\n",
    "Here's an example to demonstrate how expand_as can be used to match the results of broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([[1, 2, 3]])  # Shape: (1, 3)\n",
    "B = torch.tensor([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "B_expanded = B.expand_as(A)\n",
    "\n",
    "C = A + B_expanded\n",
    "\n",
    "print(C)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have tensors A and B with different shapes. Tensor A has shape (1, 3), and tensor B has shape (3,). To perform elementwise addition between A and B, we need to ensure that their shapes are compatible.\n",
    "\n",
    "The expand_as method is used to expand tensor B to match the shape of tensor A. It automatically expands the dimensions of B so that it has the same shape as A. The resulting tensor, B_expanded, has shape (1, 3), matching the shape of A.\n",
    "\n",
    "Now, we can perform elementwise addition between A and B_expanded to obtain tensor C, which has the same shape as A. The addition is performed elementwise, adding the corresponding elements from A and B_expanded.\n",
    "\n",
    "By using expand_as, we ensure that the shapes of the tensors are compatible for elementwise operations, allowing us to obtain the desired result while avoiding broadcasting errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dd506df1d88dd73352eb3e09472b4c7cc578a4982bd023ad748be4511128f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
